{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "286e744f-6426-42b4-b032-94c0aa4ea816",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS ###\n",
    "\n",
    "# Quantum libraries:\n",
    "import pennylane as qml\n",
    "#from pennylane \n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "from functools import partial\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly\n",
    "\n",
    "# Other\n",
    "import sys, os\n",
    "import time\n",
    "import copy\n",
    "import tqdm\n",
    "import joblib # Writing and loading\n",
    "from noisyopt import minimizeSPSA\n",
    "import optuna # Automatic tuning tool\n",
    "import multiprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"For Hamiltonians, the eigenvalues will be computed numerically. This may be computationally intensive for a large number of wires.Consider using a sparse representation of the Hamiltonian with qml.SparseHamiltonian.\")\n",
    "##############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97dfcda1-68a4-4c17-9760-db51c7dcf209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My functions:\n",
    "sys.path.insert(0, '../')\n",
    "import vqe_functions as vqe\n",
    "import qcnn_functions as qcnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1239301-e442-4a66-ac06-f19065b42431",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "J = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55f71e7b-4025-49f7-9cf4-2e64e20d9b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEAN DATA:\n",
      "______________________________\n",
      "Size of Data Set: 100\n",
      "Size of Training Set: 80\n",
      "Size of Test Set    : 20\n"
     ]
    }
   ],
   "source": [
    "# Load data and separate in training and test set\n",
    "data = joblib.load('../vqe_states_job/0noiseN'+str(N)+'.job')\n",
    "\n",
    "train_index = np.sort(np.random.choice(np.arange(len(data)), size=int(0.8*len(data)), replace=False ))\n",
    "\n",
    "X_train, Y_train = [], []\n",
    "X_test, Y_test   = [], []\n",
    "X, Y             = [], []\n",
    "for i in range(len(data)): \n",
    "    if i in train_index:\n",
    "        X_train.append(data[i][0])\n",
    "        Y_train.append(data[i][1])\n",
    "        X.append(data[i][0])\n",
    "        Y.append(data[i][1])\n",
    "    else:\n",
    "        X_test.append(data[i][0])\n",
    "        Y_test.append(data[i][1])\n",
    "        X.append(data[i][0])\n",
    "        Y.append(data[i][1])\n",
    "        \n",
    "X_train, Y_train = jnp.array(X_train), jnp.array(Y_train)\n",
    "X_test, Y_test   = jnp.array(X_test), jnp.array(Y_test)\n",
    "\n",
    "\n",
    "print('CLEAN DATA:')\n",
    "print('______________________________')\n",
    "print('Size of Data Set: {0}'.format(len(data)))\n",
    "print('Size of Training Set: {0}'.format(np.shape(X_train)[0]))\n",
    "print('Size of Test Set    : {0}'.format(np.shape(X_test)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "74cedb11-9e93-465f-bea9-5c4447977f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqe_circuit_fun = vqe.vqe_circuit\n",
    "qcnn_circuit_fun = qcnn.qcnn_circuit\n",
    "\n",
    "sizes_train = [1, 10, 25, 50, 60, 70, 80]\n",
    "epochs  = 3000\n",
    "n_iters = 100\n",
    "lr      = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ece297a-0cfe-4cb2-b5a2-2d01645d005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = qml.device(\"default.qubit.jax\", wires = N, shots = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9f45a9-b8db-41a8-bb70-36bb7d07262c",
   "metadata": {},
   "source": [
    "* 1. Split Test and Training set as 20-80 (This was not done randomly, the split was done so the test points are as sparse (and different) as possible)\n",
    "* 2. We choose different sizes of the training set [npoints_list]\n",
    "* 3. For npoints in npoints_list:\n",
    "    * Draw randomly a subset of npoints from the training set\n",
    "    * Train the QCNN just with those samples\n",
    "    * Get the Loss and Accuracy on the Test Set\n",
    "    * Get the mean and variance for the QCNNs trained with npoitns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca2c2fd9-9c58-454c-8d90-c63f38acbcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_npoints_accuracies(X_train, Y_train, X_test, Y_test, device, npoints_list, n_iters, epochs, testdata_ratio = 0.2, plot = True):\n",
    "    '''\n",
    "    From the same VQE parameters we want to train many times a QCNN with different samples\n",
    "    in order to find what is the average accuracy n-training points can reach\n",
    "    '''\n",
    "    \n",
    "    @qml.qnode(device, interface=\"jax\")\n",
    "    def qcnn_circuit_prob(params_vqe, params, N):\n",
    "        qcnn_circuit_fun(params_vqe, vqe_circuit_fun, params, N)\n",
    "    \n",
    "        return qml.probs(wires = N - 1)\n",
    "    \n",
    "    def compute_cross_entropy(X, Y, params):\n",
    "        v_qcnn_prob = jax.vmap(lambda v:  qcnn_circuit_prob(v, params, N) )\n",
    "\n",
    "        predictions = v_qcnn_prob(X)\n",
    "        logprobs = jnp.log(predictions)\n",
    "\n",
    "        nll = jnp.take_along_axis(logprobs, jnp.expand_dims(Y, axis=1), axis=1)\n",
    "        ce = -jnp.mean(nll)\n",
    "\n",
    "        return ce\n",
    "    \n",
    "    def compute_cross_entropy_n_accuracy(X, Y, params):\n",
    "        v_qcnn_prob = jax.vmap(lambda v:  qcnn_circuit_prob(v, params, N) )\n",
    "\n",
    "        predictions = v_qcnn_prob(X)\n",
    "        logprobs = jnp.log(predictions)\n",
    "\n",
    "        nll = jnp.take_along_axis(logprobs, jnp.expand_dims(Y, axis=1), axis=1)\n",
    "        ce = -jnp.mean(nll)\n",
    "\n",
    "        return ce, 100*jnp.sum(jnp.argmax(predictions, axis = 1) == Y)/len(Y)\n",
    "    \n",
    "    test_get_results  = jax.jit(lambda p: compute_cross_entropy_n_accuracy(X_test, Y_test, p) ) \n",
    "    wrap_jax_train = lambda x,y: jax_train(epochs, lr, N, device, vqe_circuit_fun, qcnn_circuit_fun, x, y)\n",
    "    \n",
    "    loss_means = []\n",
    "    loss_devs  = []\n",
    "    \n",
    "    acc_means = []\n",
    "    acc_devs  = []\n",
    "    \n",
    "    for prog, npoints in enumerate(npoints_list):\n",
    "        pbar = tqdm.tqdm(total = n_iters, position=0, leave=True)\n",
    "        pbar.set_description('{0}/{1}'.format(prog+1, len(npoints_list)) )\n",
    "        \n",
    "        d_compute_cross_entropy = jax.jit(jax.grad(lambda p, X_sub, Y_sub: compute_cross_entropy(X_sub, Y_sub, p) ) )\n",
    "        \n",
    "        # Training function\n",
    "        def jax_train(epochs, lr, N, device, vqe_circuit_fun, qcnn_circuit_fun, X_sub, Y_sub):\n",
    "        \n",
    "            n_params = qcnn_circuit_fun([0]*1000, vqe_circuit_fun, [0]*1000, N)\n",
    "            params = np.array([np.pi/4]*n_params)\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                params -= lr*d_compute_cross_entropy(params, X_sub, Y_sub)\n",
    "\n",
    "            return params\n",
    "        \n",
    "        loss_point, acc_point = [], []\n",
    "            \n",
    "        for it in range(n_iters):\n",
    "            # Choose a random subset of the training set of size npoints\n",
    "            train_idx_it = np.random.choice(np.arange(len(Y_train)), npoints, replace=False)\n",
    "            X_train_it = jnp.array(X_train[train_idx_it])\n",
    "            Y_train_it = jnp.array(Y_train[train_idx_it])\n",
    "            \n",
    "            params = wrap_jax_train(X_train_it, Y_train_it)\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "            loss, acc = test_get_results(params)\n",
    "            loss_point.append(loss)\n",
    "            acc_point.append(acc)\n",
    "            \n",
    "        loss_means.append(np.mean(loss_point))\n",
    "        loss_devs.append(np.std(loss_point))\n",
    "    \n",
    "        acc_means.append(np.mean(acc_point))\n",
    "        acc_devs.append(np.std(acc_point))\n",
    "        \n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(10,10))\n",
    "            \n",
    "        ax[0].plot(np.arange(len(npoints_list)), loss_means, color='indigo', lw = 2, alpha = 0.3)\n",
    "        ax[0].errorbar(np.arange(len(npoints_list)), loss_means, yerr=3*np.array(loss_devs), fmt='o', color='indigo',\n",
    "                       ecolor='blueviolet', elinewidth=3, capsize=0)\n",
    "        ax[0].set_xticks(np.arange(len(npoints_list)))\n",
    "        ax[0].set_xticklabels(npoints_list)\n",
    "        ax[0].grid(True)\n",
    "        ax[0].set_title('Losses on Test Set'.format(N,J))\n",
    "        ax[0].set_xlabel('# points in Training Set')\n",
    "        ax[0].set_ylabel('Cross-entropy')\n",
    "\n",
    "        ax[1].plot(np.arange(len(npoints_list)), acc_means, color='red', ms = 7, alpha = 0.3)\n",
    "        ax[1].errorbar(np.arange(len(npoints_list)), acc_means, yerr=3*np.array(acc_devs),fmt='o', color='red',\n",
    "                       ecolor='red', elinewidth=3, capsize=0)\n",
    "        ax[1].set_xticks(np.arange(len(npoints_list)))\n",
    "        ax[1].set_xticklabels(npoints_list)\n",
    "        ax[1].grid(True)\n",
    "        ax[1].set_title('Accuracies on Test Set')\n",
    "        ax[1].set_xlabel('# points in Training Set')\n",
    "        ax[1].set_ylabel('(%)')\n",
    "        \n",
    "    return loss_means, loss_devs, acc_means, acc_devs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80d2b0bf-68cc-4798-8904-f6d65ea40bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/7:  56%|████████████████████▋                | 56/100 [04:07<03:09,  4.30s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss_means, loss_devs, acc_means, acc_devs \u001b[38;5;241m=\u001b[39m \u001b[43mreduced_npoints_accuracies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mtestdata_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36mreduced_npoints_accuracies\u001b[0;34m(X_train, Y_train, X_test, Y_test, device, npoints_list, n_iters, epochs, testdata_ratio, plot)\u001b[0m\n\u001b[1;32m     66\u001b[0m X_train_it \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(X_train[train_idx_it])\n\u001b[1;32m     67\u001b[0m Y_train_it \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(Y_train[train_idx_it])\n\u001b[0;32m---> 69\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mwrap_jax_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_it\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_it\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     73\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m test_get_results(params)\n",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36mreduced_npoints_accuracies.<locals>.<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ce, \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mjnp\u001b[38;5;241m.\u001b[39msum(jnp\u001b[38;5;241m.\u001b[39margmax(predictions, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m Y)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(Y)\n\u001b[1;32m     35\u001b[0m test_get_results  \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mjit(\u001b[38;5;28;01mlambda\u001b[39;00m p: compute_cross_entropy_n_accuracy(X_test, Y_test, p) ) \n\u001b[0;32m---> 36\u001b[0m wrap_jax_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x,y: \u001b[43mjax_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvqe_circuit_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqcnn_circuit_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m loss_means \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     39\u001b[0m loss_devs  \u001b[38;5;241m=\u001b[39m []\n",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36mreduced_npoints_accuracies.<locals>.jax_train\u001b[0;34m(epochs, lr, N, device, vqe_circuit_fun, qcnn_circuit_fun, X_sub, Y_sub)\u001b[0m\n\u001b[1;32m     54\u001b[0m params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m*\u001b[39mn_params)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 57\u001b[0m     params \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m*\u001b[39m\u001b[43md_compute_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_sub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m params\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_means, loss_devs, acc_means, acc_devs = reduced_npoints_accuracies(X_train, Y_train, X_test, Y_test, device, sizes_train, n_iters, epochs,\n",
    "                               testdata_ratio = 0.2, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ba1899-31dd-484e-b4d7-221afbdc3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump((loss_means, loss_devs), '../../data/small_sets/loss.job')\n",
    "joblib.dump((acc_means, acc_devs), '../../data/small_sets/acc.job')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ce3ee-6837-48f1-be30-f428117ac7f3",
   "metadata": {},
   "source": [
    "joblib.dump((loss_means, loss_devs), '/data/smonaco/loss.job')\n",
    "joblib.dump((acc_means, acc_devs), '/data/smonaco/acc.job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac9eae-7549-41bc-91bd-8ac33a4a3419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
